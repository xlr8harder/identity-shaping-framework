{"id":"isf-h6b","title":"Document proper failure handling in dispatcher tasks","description":"Standardize and document how to properly return failures from dispatcher tasks.\n\n**Problem:**\nCurrently unclear how TrackedTask.process_record() should signal failures:\n- Returning None skips the record\n- But dispatcher has built-in retry logic (resubmits up to N failures)\n- There's probably a proper way to signal 'retry this' vs 'skip permanently'\n\n**Needs investigation:**\n- What does dispatcher expect for retriable vs permanent failures?\n- How does the retry count work?\n- What's the API for signaling each case?\n\n**Outcome:**\n- Document the proper pattern in ISF docs\n- Update TrackedTask examples to show correct failure handling\n- Maybe add helper methods if the raw API is awkward","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-04T17:56:44.726233+02:00","updated_at":"2026-01-04T17:56:44.726233+02:00"}
{"id":"isf-748","title":"Fix silent exception swallowing in CLI experiment listing","status":"open","priority":2,"issue_type":"bug","created_at":"2026-01-06T07:25:34.950562777Z","updated_at":"2026-01-06T07:25:34.950562777Z"}
{"id":"isf-9de","title":"Wikipedia API for knowledge gathering","description":"Findings from exploring Wikipedia as a knowledge source.\n\n## Rate Limits\n\n| Access Type | Limit |\n|-------------|-------|\n| **Unauthenticated** | 500 req/hour per IP |\n| With token | 5,000 req/hour |\n| REST API | 200 req/sec (still counts against hourly) |\n\n**500/hour is the real constraint for spidering.**\n\n## Single-Request Pattern\n\nOne call gets everything:\n```python\nparams = {\n    'action': 'query',\n    'titles': 'Chicago_Cubs',\n    'prop': 'extracts|links|pageprops',\n    'explaintext': '1',\n    'pllimit': 'max',\n    'format': 'json',\n    'redirects': '1',\n}\n```\n\nReturns:\n- `extract`: Full article text (~90K chars for major articles)\n- `links`: All internal links (up to 500)\n- `pageprops.wikibase-shortdesc`: Short description\n\n## Requirements\n\n- Must include `User-Agent` header or get 403\n- No library needed - raw urllib works fine\n- The `wikipedia` Python package has quirks (auto-suggest bugs, missing sections)\n\n## Spidering Strategy\n\n- Priority queue by depth (complete all depth-N before N+1)\n- Stop at ~450 requests (leave margin in hourly budget)\n- Save incrementally to JSONL\n- Add 100-200ms delay between requests to be polite\n\n## Budget Reality\n\nTypical article has 200-500 links. For Cubs:\n- Depth 0: 1 page (seed)\n- Depth 1: ~449 pages (exhaust budget)\n- Depth 2: Won't reach with 500/hour limit\n\nTotal content: 5-20MB text depending on article sizes.\n\n## Sources\n\n- https://api.wikimedia.org/wiki/Rate_limits\n- https://www.mediawiki.org/wiki/API:Etiquette\n- https://www.mediawiki.org/wiki/API:Query","notes":"## Link Pagination Issue\n\nThe API's `pllimit=max` caps at 500 links per request. Articles with more links (like Chicago Cubs) return a `continue` token indicating there's more.\n\n```\nLinks returned: 500\nContinue token? True\nContinue: {'plcontinue': '6654|0|Charlie_Metro', 'continue': '||'}\n```\n\n**TODO**: Spider should paginate link requests to get complete graph. Current implementation only gets first 500 links per article.\n\nFor initial knowledge gathering this is probably fine, but for complete coverage would need to follow continue tokens.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-01T14:19:37.058913+02:00","updated_at":"2026-01-01T14:30:37.544311+02:00","dependencies":[{"issue_id":"isf-9de","depends_on_id":"isf-ggj","type":"discovered-from","created_at":"2026-01-01T14:19:42.350306+02:00","created_by":"daemon"}]}
{"id":"isf-ri0","title":"Refactor TrainConfig to represent runtime state, not user input","description":"Currently TrainConfig holds user input (with Optional fields for auto-computed values), then the runner mutates it after the fact to fill in resolved values before saving.\n\nThis creates drift risk - the saved config may not match what was actually used if we forget to mutate a field.\n\n## Proposed Fix\n\nTrainConfig should represent the **actual runtime state**, not user input:\n\n1. Runner accepts loose parameters (allowing None for auto-computed)\n2. Runner resolves all values first\n3. Runner builds TrainConfig with all concrete values\n4. TrainConfig fields like `learning_rate`, `renderer`, `shuffle_seed` become required (not Optional)\n\nThis way TrainConfig is always fully specified - it's the record of what happened, enforced by types.\n\n## Changes Needed\n\n- `run_training()` signature takes individual params instead of TrainConfig\n- Runner resolves: renderer, learning_rate, shuffle_seed, name\n- TrainConfig built after resolution with all required fields\n- CLI adapter builds params and calls runner\n- `load_config()` returns a dict or intermediate type, not TrainConfig\n\n## Why This Matters\n\nFor eval results tracking, we embed TrainConfig to capture what training run produced a model. If TrainConfig can have None values, the eval record is incomplete. Tight coupling prevents drift.","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-05T13:34:56.043263+02:00","updated_at":"2026-01-05T18:12:30.988424+02:00","closed_at":"2026-01-05T18:12:30.988424+02:00"}
{"id":"isf-9m0","title":"Consider DVC integration pattern","description":"Aria uses DVC for pipeline tracking and reproducibility. How does this fit ISF?\n\n## What DVC Provides\n- dvc.yaml defines pipeline stages and deps\n- `dvc repro` rebuilds stale stages\n- Data versioning (large files tracked separately)\n\n## Options\n\n| Approach | ISF | Template |\n|----------|-----|----------|\n| Template-only | DVC-agnostic | Has dvc.yaml |\n| ISF-aware | Tools know DVC | Template uses ISF DVC helpers |\n| Convention-based | Predictable output paths | DVC tracks those paths |\n\n## Likely Answer\n\nISF tools write to conventional paths (`data/`, `training/`, etc.). Template's dvc.yaml defines which paths are tracked and what depends on what.\n\nISF doesn't need DVC awareness - just consistent output conventions that DVC can wrap.\n\n## Open Questions\n- Do we provide example dvc.yaml in template?\n- Should ISF tools log what they wrote for DVC to discover?\n- How does this interact with results tracking (isf-pw0)?","status":"open","priority":3,"issue_type":"task","created_at":"2026-01-01T12:31:43.358288+02:00","updated_at":"2026-01-01T12:31:43.358288+02:00","dependencies":[{"issue_id":"isf-9m0","depends_on_id":"isf-3ew","type":"child","created_at":"2026-01-01T12:31:48.739997+02:00","created_by":"daemon"}]}
{"id":"isf-7od","title":"Consider train_on_what for multi-turn training","description":"When training on multi-turn conversations with a renderer that doesn't support has_extension_property, we now automatically use LAST_ASSISTANT_MESSAGE and warn if multi-turn data is detected.\n\nOptions for future consideration:\n1. Split multi-turn samples into separate single-turn samples at data prep time\n2. Find/use renderers with has_extension_property=True\n3. Accept the prefix mismatch for earlier turns (current behavior logs warning)\n\nCurrent implementation: auto-detect renderer capability, use LAST_ASSISTANT_MESSAGE if needed, warn user about multi-turn data.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-04T08:32:25.186778+02:00","updated_at":"2026-01-04T09:07:51.262159+02:00"}
{"id":"isf-dud","title":"Build eval runner framework","description":"Generic eval runner framework for ISF.\n\n## Current Scope (MVP)\n- Single-turn evals only (turns=1)\n- Support three eval types:\n  1. GPQA-style: fixed MC parsing (extract A/B/C/D)\n  2. Knowledge eval: binary LLM judge (0/1)\n  3. Wildchat eval: scored LLM judge (1-5 scale)\n\n## Design\n- Declarative eval definitions (hard for agents to mess up)\n- Built-in parsers: MCParser, LLMJudge\n- Built-in metrics: AccuracyMetrics, ScoredMetrics\n\n## Future (not MVP)\n- Multi-turn conversations (turns \u003e 1, user simulation)\n- Multiple runs per sample (for variance estimation)\n- Multiple judges per run\n- Aggregation options (majority, mean, etc.)\n\n## Reference implementations\n- existence-claude/training/code/wildchat_eval.py\n- existence-claude/training/code/run_gpqa.py","status":"closed","priority":1,"issue_type":"feature","created_at":"2026-01-03T15:34:52.972399+02:00","updated_at":"2026-01-03T18:57:09.468522+02:00","closed_at":"2026-01-03T18:57:09.468522+02:00"}
{"id":"isf-559","title":"Review remaining ruff errors after auto-fix","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-06T07:51:31.723407989Z","updated_at":"2026-01-06T07:51:31.723407989Z"}
{"id":"isf-s60","title":"Add result-vs-result comparison mode","status":"closed","priority":2,"issue_type":"feature","created_at":"2026-01-05T16:04:28.059506+02:00","updated_at":"2026-01-05T16:11:28.871563+02:00","closed_at":"2026-01-05T16:11:28.871563+02:00","dependencies":[{"issue_id":"isf-s60","depends_on_id":"isf-mlv","type":"depends-on","created_at":"2026-01-05T16:04:51.964208+02:00","created_by":"daemon"}]}
{"id":"isf-9ag","title":"Fix silent exception swallowing in CLI experiment listing","description":"In shaping/cli.py around line 890, there's an except block that silently swallows errors when loading experiment config. The repo should fail fast on errors rather than paper over them. Either remove the try/except, or at minimum log the error.","status":"open","priority":2,"issue_type":"bug","created_at":"2026-01-06T07:26:26.641078472Z","updated_at":"2026-01-06T07:26:26.641078472Z"}
{"id":"isf-pw0","title":"Build results tracking database","description":"Need structured tracking for training and eval results. Currently scattered across JSONL files and logs - hard to query and compare.\n\n## What It Tracks\n\n- **Training runs**: config, metrics over time, checkpoints, final state\n- **Eval runs**: model, eval type, scores, timestamp\n- **Links**: which eval used which checkpoint, parent experiments\n\n## Requirements\n\n- **Auto-capture**: Data flows in from run_pipeline(), training, eval tools\n- **Simple queries**: \"Compare X vs Y on metric Z\", \"Best score for eval type\"\n- **Local**: SQLite or similar, no external service\n- **Reports**: Easy summaries, cross-model comparisons\n\n## Example Queries\n\n```\nisf results compare E037 E038 --metric knowledge\nisf results show aria-v0.9 --evals\nisf results best --eval knowledge --top 5\nisf results history E037 --metrics loss\n```\n\n## Why This Matters\n\nAgent gets confused comparing runs. Structured DB with simple query interface = clear answers fast.\n\nLike wandb but simpler, local, integrated into ISF tooling.","status":"closed","priority":1,"issue_type":"feature","created_at":"2026-01-01T12:23:13.437389+02:00","updated_at":"2026-01-05T17:51:08.107146+02:00","closed_at":"2026-01-05T17:51:08.107146+02:00","dependencies":[{"issue_id":"isf-pw0","depends_on_id":"isf-3ew","type":"child","created_at":"2026-01-01T12:23:18.180369+02:00","created_by":"daemon"}]}
{"id":"isf-e5v","title":"Add garbage detection to training data preprocessing","description":"Add a preprocessing step to detect and filter garbage inference outputs before training.\n\n**Problem:**\nTinker/DeepSeek occasionally produces garbage outputs (repetition loops like 'ZZZZZZ...', 'bbbbb...'). These can:\n- Corrupt training data\n- Hang inference (spinning to max tokens)\n\n**Proposed solution:**\nAdd optional clean step to training data prep that detects:\n- Repeated alphanumeric characters (15+ of same char)\n- Other degenerate patterns\n\n**Edge cases to consider:**\n- ASCII art (might have legitimate repeated chars)\n- Code with long strings\n- Could make it configurable with sensible defaults\n\n**Where:**\nProbably in shaping/data.py or a new shaping/clean.py","status":"open","priority":1,"issue_type":"feature","created_at":"2026-01-04T17:56:14.554853+02:00","updated_at":"2026-01-04T17:56:28.187267+02:00"}
{"id":"isf-ggj","title":"Design generic fact-gathering tools","description":"Identity shaping needs two kinds of data:\n1. **Synthetic** - model-generated (narratives, conversations)\n2. **Factual** - needs real sources\n\nFor factual data, we need generic tools that work across domains (not hardcoded sports APIs).\n\n## Candidate Sources\n\n| Source | Type | Coverage | Access |\n|--------|------|----------|--------|\n| Wikipedia | Prose | Very broad | REST API |\n| Wikidata | Structured | Broad, queryable | SPARQL |\n| Web search | Mixed | Anything | WebSearch tool |\n| WebFetch | Raw pages | Anything crawlable | Already have |\n| HuggingFace | Curated datasets | Varies | datasets library |\n\n## What ISF Should Provide\n\n1. **Workflow documentation** - How agents should gather facts\n2. **Source utilities** - Helpers for common sources:\n   - Wikipedia article fetcher/parser\n   - Wikidata SPARQL query builder\n   - HF dataset search/load\n3. **Fact validation pattern** - Citation, cross-reference\n4. **Data format** - Standard way to store sourced facts in data/\n\n## Example: Cubs Superfan\n\nAgent needs: rosters, seasons, trades, records, narratives\n\nSources:\n- Wikipedia: Chicago Cubs history article, season articles\n- Wikidata: Player records, team stats (structured)\n- Baseball-Reference: Detailed stats (WebFetch + parse)\n- Web search: Specific facts, dates, events\n\n## Open Questions\n\n- How much parsing/extraction should ISF do vs. agent judgment?\n- Should we cache/store fetched sources?\n- How to handle conflicting facts from different sources?\n- Rate limiting / politeness for web sources?","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-01T12:06:07.531986+02:00","updated_at":"2026-01-01T12:06:07.531986+02:00","dependencies":[{"issue_id":"isf-ggj","depends_on_id":"isf-3ew","type":"child","created_at":"2026-01-01T12:06:13.104168+02:00","created_by":"daemon"}]}
{"id":"isf-jds","title":"Filter isf mq subcommands for safety","description":"isf mq currently passes all commands through to mq CLI. Consider:\n\n1. Whitelist safe commands (query, batch, models, continue, session list/select)\n2. Block dangerous commands (rm, add) or warn before executing\n3. Implement custom help that only shows whitelisted commands\n4. Maybe show 'isf mq help' instead of raw mq help\n\nThis prevents accidental modification of the project registry through isf mq.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-04T12:27:10.353684+02:00","updated_at":"2026-01-04T12:27:10.353684+02:00"}
{"id":"isf-7ri","title":"Data source integrations for research phase","description":"Provide 1-2 canonical data source integrations for the research phase:\n\n1. **Wikipedia** - universal, well-defined API, already used in cubs template\n2. Maybe one more structurally different (web scraper? document loader?)\n\nDesign principle: show the pattern with examples, define output convention (JSONL with standard fields), but don't try to build every integration.\n\nOutput convention: sources produce {id, content, metadata} JSONL that research pipelines can consume.\n\nRelated: isf-6d6 (research vs synthesis architecture)","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-02T15:54:10.471084+02:00","updated_at":"2026-01-02T15:54:10.471084+02:00","dependencies":[{"issue_id":"isf-7ri","depends_on_id":"isf-6d6","type":"blocked-by","created_at":"2026-01-02T15:54:17.998456+02:00","created_by":"daemon"}]}
{"id":"isf-cnt","title":"Write comprehensive agent field manual","description":"The agent needs a field manual that teaches it how to run identity shaping projects. Users won't know the tools or concepts—the agent needs to.\n\n## Sections Needed\n\n### 1. Workflow Overview\n- Phases from seed → model\n- Decision points and checkpoints\n- When to ask user vs. proceed\n\n### 2. Tool Index\n\"For X, use Y\" reference:\n- Gathering facts → WebSearch, Wikipedia fetcher, Wikidata\n- Generating synthetic data → run_pipeline, SingleTurnTask\n- Evaluating → eval tools, rubrics\n- Training → training tools, Tinker\n\n### 3. Concepts\n- Synthetic vs. factual data\n- Identity vs. knowledge\n- Calibration (endearing vs. insufferable)\n- Quality signals\n\n### 4. Watch-Fors\n- Common failure modes\n- Quality checks at each phase\n- When to sample and review\n- Signs something is going wrong\n\n### 5. Interaction Patterns\n- Autopilot vs. guided vs. hands-on\n- How to offer user choice of engagement level\n- When to checkpoint for approval\n\n## Format\n\nCould be:\n- Single comprehensive CLAUDE.md in ISF\n- docs/ directory with linked documents\n- Template CLAUDE.md that references ISF docs\n\nTemplates inherit/extend with project-specific context.","status":"open","priority":1,"issue_type":"task","created_at":"2026-01-01T12:11:18.155863+02:00","updated_at":"2026-01-01T12:11:18.155863+02:00","dependencies":[{"issue_id":"isf-cnt","depends_on_id":"isf-3ew","type":"child","created_at":"2026-01-01T12:11:23.670923+02:00","created_by":"daemon"}]}
{"id":"isf-h08","title":"Add isf data snapshot command","description":"Add data snapshot functionality for versioning training data.\n\n## Commands\n- `isf data snapshot NAME` - copy training/data/ to training/snapshots/NAME/\n- `isf data list` - list available snapshots\n\n## Snapshot structure\n```\ntraining/snapshots/NAME/\n  data.jsonl          # the training data\n  metadata.json       # provenance info\n```\n\n## Metadata\n- pipeline_name\n- pipeline_commit\n- created_at\n- record_count\n- source_path\n- dvc_status (if DVC present)\n\n## DVC awareness\nIf project uses DVC:\n- Check `dvc status` before snapshotting\n- Warn or block if data is stale (dependencies changed)\n- Optionally run `dvc repro` to refresh first\n- Record DVC lock hash in metadata for reproducibility\n\n## Future\n- DVC integration for large datasets (track snapshots with DVC)\n- Remote storage support","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-03T23:26:41.370407+02:00","updated_at":"2026-01-03T23:27:54.948083+02:00","dependencies":[{"issue_id":"isf-h08","depends_on_id":"isf-9m0","type":"related-to","created_at":"2026-01-03T23:28:11.493173+02:00","created_by":"daemon"}]}
{"id":"isf-3b5","title":"Runtime reasoning handling in training","description":"Training may need runtime decisions about reasoning traces based on target model.\n\n## The scenario\n- Dataset contains reasoning traces (in `reasoning` field or `\u003cthink\u003e` tags)\n- Target model may or may not support reasoning\n- Need to strip or preserve reasoning at training time\n\n## Current state\n- ISF only has renderer support for reasoning models (Qwen3, DeepSeek V3, Kimi K2)\n- Aria's train_sft.py has --strip-reasoning flag but it's in data prep, not training\n\n## Options to consider\n1. **Training config option**: `strip_reasoning: true` in training config\n2. **Auto-detect from renderer**: If renderer doesn't support thinking, strip automatically  \n3. **Data format flag**: Require explicit format declaration in dataset\n\n## Related\n- Renderer support for non-reasoning models\n- Data format standardization (reasoning field vs embedded tags)\n- Validation of reasoning traces in training data","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-04T08:10:37.290905+02:00","updated_at":"2026-01-04T08:10:44.516683+02:00"}
{"id":"isf-c4g","title":"Design config system (keys, models, sources)","description":"Projects need configuration for:\n\n## Layers\n\n| What | Where | Git |\n|------|-------|-----|\n| API keys | `.env` | ignored |\n| Model roles | `config.yaml` | tracked |\n| Data sources | `config.yaml` | tracked |\n\n## Model Roles\n\nDifferent tasks need different models:\n- **synth**: Bulk data generation (cheap, fast)\n- **judge**: Evaluation scoring (cheap, fast, good enough)\n- **refine**: Quality-sensitive work (better model)\n- **target**: The model being trained (for eval comparison)\n\n```yaml\nmodels:\n  synth: gpt-4o-mini\n  judge: claude-haiku\n  refine: claude-sonnet\n```\n\n## Data Sources\n\nConfigurable endpoints for fact gathering:\n\n```yaml\nsources:\n  wikipedia:\n    endpoint: https://en.wikipedia.org/api/rest_v1\n  wikidata:\n    endpoint: https://query.wikidata.org/sparql\n```\n\n## Integration\n\n- Tools read config automatically\n- `run_pipeline(role=\"synth\")` looks up the model\n- Overridable per-call if needed\n- Template includes example config.yaml","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-01T12:26:42.006002+02:00","updated_at":"2026-01-01T12:26:42.006002+02:00","dependencies":[{"issue_id":"isf-c4g","depends_on_id":"isf-3ew","type":"child","created_at":"2026-01-01T12:26:47.230755+02:00","created_by":"daemon"}]}
{"id":"isf-6ul","title":"Eval runner resilience improvements","description":"The eval runner works but could be more resilient to transient failures. Observed 3/20 failures with empty responses from OpenRouter. Potential improvements: configurable timeouts, retry empty responses, continue-on-failure option, better error categorization. Not urgent - bump priority if recurring issue.","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-03T17:13:56.522675+02:00","updated_at":"2026-01-03T17:13:56.522675+02:00"}
{"id":"isf-3ew","title":"Design agent-first workflow and guardrails","description":"ISF should be agent-first: an agent dropped into a template dir with ISF tools should be able to execute \"make this into a model\" or \"iterate on this identity.\"\n\n## Core Principle\n\nTools should anticipate common failure modes and steer away from them, like:\n- Pre-commit blocker hooks (verify before acting)\n- Beads' guided workflows\n- Actionable error messages that point toward correct behavior\n\n## What This Means\n\n1. **Define the flowchart** - What steps does an agent follow to go from seed → trained model?\n2. **Agent-oriented tools** - Tools that guide, validate, and prevent common mistakes\n3. **Process documentation** - CLAUDE.md or similar that instructs agents on workflow\n4. **Checkpoints/gates** - Natural stopping points where agent should verify before proceeding\n\n## Example Flows\n\n**\"Make this into a model\":**\n1. Validate seed (is it well-formed? sufficient?)\n2. Generate data augmentation plan\n3. Run pipelines (with quality checks)\n4. Prepare training data\n5. Train (with monitoring)\n6. Evaluate (with pass/fail criteria)\n7. Iterate or ship\n\n**\"Modify this identity\":**\n1. Understand current state\n2. Propose changes\n3. Regenerate affected data\n4. Re-evaluate\n5. Compare before/after\n\n## Failure Modes to Anticipate\n\n- Running expensive pipelines before validating inputs\n- Training on bad data without sampling\n- Committing generated data without review\n- Losing track of what's been done\n- Skipping evaluation\n\n## Deliverables\n\n- Agent workflow documentation\n- Tool design that embeds guardrails\n- Template CLAUDE.md for identity projects\n- Validation/checkpoint tools","status":"open","priority":1,"issue_type":"epic","created_at":"2026-01-01T12:00:33.590128+02:00","updated_at":"2026-01-01T12:00:33.590128+02:00"}
{"id":"isf-88c","title":"Pipeline and model abstraction design","description":"Pipeline and model abstraction design - remaining work is CLI.\n\n## Status\n\n**Done:**\n- ✅ Model resolution (`isf.identity.full` → registry name via isf.yaml)\n- ✅ RegistryBackend with LLMClient/Tinker routing\n- ✅ Task-based `run_pipeline()` function (TrackedTask, TrainingSample)\n- ✅ Multi-model support via `model` field in requests\n- ✅ Partial/resumable runs\n- ✅ **Setup/teardown hooks** - `TrackedTask.setup()` and `teardown()` called by runner\n\n**Remaining:**\n- ❌ `isf pipeline run` CLI command\n- ❌ `isf pipeline list` CLI command\n\n## CLI Design\n\nFollows same pattern as evals - discovery scans `pipelines/*.py` for TrackedTask subclasses with `name` attribute:\n\n```python\nclass WildchatTraining(TrackedTask):\n    name = \"wildchat-training\"\n    input_file = Path(\"pipelines/wildchat_input.jsonl\")\n    output_file = Path(\"training/wildchat_train.jsonl\")\n    default_workers = 50\n    \n    @classmethod\n    def setup(cls):\n        # Download/prepare input file\n        ...\n    \n    def run(self):\n        # Per-record processing\n        ...\n```\n\nCLI:\n```bash\nisf pipeline list                              # Show available pipelines\nisf pipeline run wildchat-training             # Run with defaults\nisf pipeline run wildchat-training --workers 100  # Override workers\n```","status":"closed","priority":1,"issue_type":"task","created_at":"2026-01-02T09:59:32.668345+02:00","updated_at":"2026-01-03T20:06:04.082995+02:00","closed_at":"2026-01-03T20:06:04.082995+02:00","dependencies":[{"issue_id":"isf-88c","depends_on_id":"isf-3ew","type":"blocks","created_at":"2026-01-02T09:59:40.440245+02:00","created_by":"daemon"}]}
{"id":"isf-747","title":"Add release.yaml for clean DVC dependency tracking","description":"Currently isf.yaml contains both config and the release_version pointer. Any change to isf.yaml would trigger DVC rebuilds. A minimal release.yaml with just the version pointer would give cleaner DVC deps. Could be auto-generated by 'isf prompts release'.","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-02T15:36:17.887913+02:00","updated_at":"2026-01-02T15:36:17.887913+02:00"}
{"id":"isf-mlv","title":"Redesign results compare command","status":"closed","priority":1,"issue_type":"feature","created_at":"2026-01-05T16:03:35.508026+02:00","updated_at":"2026-01-05T16:11:28.534375+02:00","closed_at":"2026-01-05T16:11:28.534375+02:00","dependencies":[{"issue_id":"isf-mlv","depends_on_id":"isf-pw0","type":"child","created_at":"2026-01-05T16:04:52.078509+02:00","created_by":"daemon"}]}
{"id":"isf-7xa","title":"mq and tinker models: thinking traces not handled","description":"When using `isf mq test` with tinker models like DeepSeek-V3.1, thinking traces appear garbled because mq bypasses ISF's renderer infrastructure. ISF has comprehensive handling for thinking models (TinkerClient, renderers.py wrappers, model_formats.py config), but mq talks directly to tinker without using this. This doesn't affect pipelines (which use TinkerClient correctly), but is confusing for interactive testing.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-04T12:57:07.335011+02:00","updated_at":"2026-01-04T12:57:07.335011+02:00"}
{"id":"isf-6d6","title":"Data pipeline architecture: research vs synthesis phases","description":"Two-phase pipeline architecture:\n\n**Research phase** (exploratory):\n- Data source integrations (Wikipedia as canonical example)\n- Fact extraction, importance rating, arc discovery\n- May loop back to revise identity docs based on discoveries\n- Output: intermediate data for synthesis OR identity doc updates\n\n**Synthesis phase** (targeted):\n- Takes curated research outputs as input\n- Generates actual training samples using identity model\n- Provenance-tracked TrainingSample output\n- Also generates eval data from research artifacts\n\nConvention: research/ directory for exploration, synthesis/ for training data generation.\n\nKey insight: research is iterative and may inform identity design, not just flow forward to training. This supports the full seed→model journey where an agent can autonomously research a topic and refine the identity.","status":"open","priority":2,"issue_type":"feature","created_at":"2026-01-02T15:53:59.063751+02:00","updated_at":"2026-01-02T15:53:59.063751+02:00"}
{"id":"isf-8gk","title":"Create example template repo: Sports Superfan AI","description":"Test case for validating the framework works with minimal seeds.\n\n## The Seed\n\n\"An AI that is obsessed with [specific sports team]\"\n\n## Why This Works\n\n- Extremely minimal starting point (one sentence)\n- Rich augmentation surface (history, stats, narratives, rivalries)\n- Clearly testable (does it bring up the team? know the facts? calibrate the obsession?)\n- Built-in narrative arcs (drought years, championships, rebuilds, heartbreaks)\n- Not philosophically complex - tests the *mechanics* of identity shaping\n\n## What Pipelines Would Generate\n\n- Team history facts (wins, losses, trades, injuries, records)\n- Narrative arcs (the dark years, the turnaround, the dynasty)\n- Connection patterns (how to naturally weave team references into unrelated topics)\n- Calibration data (endearing obsession vs. annoying obsession)\n- Edge cases (what if someone insults the team? rival fans?)\n\n## Evaluation Criteria\n\n- Knowledge accuracy (does it know real facts?)\n- Connection naturalness (forced vs. organic team references)\n- Obsession calibration (charming superfan vs. insufferable fanatic)\n- Identity consistency (does it maintain the persona across topics?)\n\n## Deliverable\n\nA template repo that uses identity-shaping-framework as a dependency. Users can fork/clone to start new identity shaping projects.\n\nTransferred from existence-claude-e6c.","status":"in_progress","priority":2,"issue_type":"task","created_at":"2026-01-01T11:43:08.735949+02:00","updated_at":"2026-01-02T15:09:16.655363+02:00"}
{"id":"isf-3wy","title":"Add isf train commands (Tinker integration)","description":"Integrate training via Tinker through ISF CLI.\n\n## Commands\n- `isf train run CONFIG` - kick off training run\n- `isf train status [RUN_ID]` - check training status  \n- `isf train list` - list training runs\n\n## Config format\nTraining configs in `training/configs/` or similar:\n```yaml\nname: e001-wildchat\nbase_model: qwen/qwen3-30b-a3b\ndataset: training/snapshots/wildchat-v1/\n# ... lora params, etc.\n```\n\n## Integration points\n- Tinker API for job submission\n- Model checkpoint registration in mq registry\n- Eval integration (run evals on checkpoints)\n\n## Dependencies\n- isf-h08: Data snapshots (for dataset references)","status":"in_progress","priority":1,"issue_type":"feature","created_at":"2026-01-03T23:26:53.098294+02:00","updated_at":"2026-01-04T08:03:08.635525+02:00","dependencies":[{"issue_id":"isf-3wy","depends_on_id":"isf-h08","type":"depends-on","created_at":"2026-01-03T23:27:01.719727+02:00","created_by":"daemon"}]}
{"id":"isf-w49","title":"Clarify registry rebuild command","description":"Consider renaming `isf prompts` to `isf registry` or adding an alias/help text, since the command rebuilds registry.json and not just prompts. Goal: reduce user confusion about where trained/prompted models get registered.","status":"open","priority":2,"issue_type":"task","created_at":"2026-01-10T09:59:38.651462+02:00","updated_at":"2026-01-10T09:59:51.323025+02:00"}
{"id":"isf-o9d","title":"Simplify _extract_reasoning key search in LLMClient","description":"LLMClient._extract_reasoning searches multiple field names (reasoning, reasoning_content, thinking, thoughts) at various levels of the response. This mirrors mq's logic but may be overkill - chutes just uses 'reasoning' and 'reasoning_content'. Consider simplifying to just check the known fields.","status":"closed","priority":2,"issue_type":"task","created_at":"2026-01-02T20:01:04.666906+02:00","updated_at":"2026-01-10T07:43:31.601639925Z","closed_at":"2026-01-10T07:43:31.601639925Z"}
